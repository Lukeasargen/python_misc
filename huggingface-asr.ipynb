{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"N:\\Music\\Audio Cassettes 1 to 5\\cassette 4 side a.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16000, (1536768,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speech, sr = librosa.load(file_path, sr=16000)\n",
    "sr, speech.shapeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ddae9862a54aaea52a635fa2bebcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/360M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "\n",
    "model_name = \"facebook/wav2vec2-base-960h\" # 360MB\n",
    "# model_name = \"facebook/wav2vec2-large-960h-lv60-self\" # 1.18GB\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "\n",
    "# model = model.to(device)\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1536768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_values = processor(speech, return_tensors=\"pt\", sampling_rate=16000)[\"input_values\"]\n",
    "input_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.03 GiB (GPU 0; 8.00 GiB total capacity; 5.69 GiB already allocated; 0 bytes free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lukeasargen\\projects\\python_misc\\huggingface-asr.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lukeasargen/projects/python_misc/huggingface-asr.ipynb#ch0000011?line=0'>1</a>\u001b[0m logits \u001b[39m=\u001b[39m model(input_values\u001b[39m.\u001b[39;49mto(device))\u001b[39m.\u001b[39mlogits\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lukeasargen/projects/python_misc/huggingface-asr.ipynb#ch0000011?line=1'>2</a>\u001b[0m logits\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1716\u001b[0m, in \u001b[0;36mWav2Vec2ForCTC.forward\u001b[1;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1705'>1706</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1706'>1707</a>\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, target_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1707'>1708</a>\u001b[0m \u001b[39m    Labels for connectionist temporal classification. Note that `target_length` has to be smaller or equal to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1710'>1711</a>\u001b[0m \u001b[39m    config.vocab_size - 1]`.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1711'>1712</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1713'>1714</a>\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1715'>1716</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav2vec2(\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1716'>1717</a>\u001b[0m     input_values,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1717'>1718</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1718'>1719</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1719'>1720</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1720'>1721</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1721'>1722</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1723'>1724</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1724'>1725</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1361\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[1;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1355'>1356</a>\u001b[0m hidden_states, extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_projection(extract_features)\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1356'>1357</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask_hidden_states(\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1357'>1358</a>\u001b[0m     hidden_states, mask_time_indices\u001b[39m=\u001b[39mmask_time_indices, attention_mask\u001b[39m=\u001b[39mattention_mask\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1358'>1359</a>\u001b[0m )\n\u001b[1;32m-> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1360'>1361</a>\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1361'>1362</a>\u001b[0m     hidden_states,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1362'>1363</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1363'>1364</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1364'>1365</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1365'>1366</a>\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1366'>1367</a>\u001b[0m )\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1368'>1369</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=1370'>1371</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:843\u001b[0m, in \u001b[0;36mWav2Vec2Encoder.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=836'>837</a>\u001b[0m         layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=837'>838</a>\u001b[0m             create_custom_forward(layer),\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=838'>839</a>\u001b[0m             hidden_states,\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=839'>840</a>\u001b[0m             attention_mask,\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=840'>841</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=841'>842</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=842'>843</a>\u001b[0m         layer_outputs \u001b[39m=\u001b[39m layer(\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=843'>844</a>\u001b[0m             hidden_states, attention_mask\u001b[39m=\u001b[39;49mattention_mask, output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=844'>845</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=845'>846</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=847'>848</a>\u001b[0m \u001b[39mif\u001b[39;00m skip_the_layer:\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:731\u001b[0m, in \u001b[0;36mWav2Vec2EncoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, output_attentions)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=728'>729</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states, attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=729'>730</a>\u001b[0m     attn_residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m--> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=730'>731</a>\u001b[0m     hidden_states, attn_weights, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=731'>732</a>\u001b[0m         hidden_states, attention_mask\u001b[39m=\u001b[39;49mattention_mask, output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=732'>733</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=733'>734</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=734'>735</a>\u001b[0m     hidden_states \u001b[39m=\u001b[39m attn_residual \u001b[39m+\u001b[39m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:650\u001b[0m, in \u001b[0;36mWav2Vec2Attention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=646'>647</a>\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mview(bsz, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, src_len) \u001b[39m+\u001b[39m attention_mask\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=647'>648</a>\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, src_len)\n\u001b[1;32m--> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=649'>650</a>\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(attn_weights, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=651'>652</a>\u001b[0m \u001b[39mif\u001b[39;00m layer_head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py?line=652'>653</a>\u001b[0m     \u001b[39mif\u001b[39;00m layer_head_mask\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,):\n",
      "File \u001b[1;32mc:\\Users\\lukeasargen\\anaconda3\\envs\\pt111\\lib\\site-packages\\torch\\nn\\functional.py:1818\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/functional.py?line=1815'>1816</a>\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/functional.py?line=1816'>1817</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/functional.py?line=1817'>1818</a>\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/functional.py?line=1818'>1819</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/lukeasargen/anaconda3/envs/pt111/lib/site-packages/torch/nn/functional.py?line=1819'>1820</a>\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.03 GiB (GPU 0; 8.00 GiB total capacity; 5.69 GiB already allocated; 0 bytes free; 6.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "logits = model(input_values.to(device)).logits\n",
    "logits.shape\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "transcription.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h (https://huggingface.co/facebook/wav2vec2-base-960h)\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "p = pipeline(\"automatic-speech-recognition\", device=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"A A A A AA  BE MALL ER BOIAL GOT ON  WOOD ARE WE GNE WHERE WE GONE I SOL BE CORT THE CARS GOING BY WONT SHE HOUT THAT WIRL THAT WORD NOW W'LL TRY WISH AT MEMANDE DECORDING IN THE NORMAL OR LOW MOD WITH T HE MICRO BONE TO PICK UP EVERYTHING IT SEEME TO BE JUST AS SENT OF IT BUT THE LOW MOMMAN WITH THE MIT OF BAN SHEE HOW WELL THE CORN THAT'S KILL BOT NOT TALKING VERY LOUD TALKING LOUD AT ALL SEEMS LIKE THE BEST WAY MAY BE  USE TA BRACK ROUND IN A LOW WOI ATWAIT RECORDING THEM\"}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = p(speech, chunk_length_s=20, stride_length_s=4)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('pt113')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02ae8a917aa381e4368c55777f1a65177308c50cf8d1fb5256f849424530e048"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
