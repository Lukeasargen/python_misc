{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install ftfy regex tqdm\n",
    "\n",
    "pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 335M/335M [00:49<00:00, 7.09MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/16\", device=device, jit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = preprocess(Image.open(\"images/dog-bird-2.jpg\")).unsqueeze(0).to(device)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 77])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"a dog\", \"a cat\", \"a bird\", \"a plane\"]\n",
    "text = clip.tokenize(labels).to(device)\n",
    "text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label:   Prob\n",
      "  a dog:  72.17\n",
      "  a cat:   1.32\n",
      " a bird:  18.53\n",
      "a plane:   7.97\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    logits_per_image, logits_per_text = model(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "lw = len(max(labels, key=lambda x: len(x)))\n",
    "row_fmt = '{:>{lw}s}: {:>6.2f}'\n",
    "print(f'{\"Label\":>{lw}s}: {\"Prob\":>6}')\n",
    "for l, p in zip(labels, probs[0]):\n",
    "    print(f'{l:>{lw}s}: {100*p:>6.2f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05264c394c9bf5c6ac8aaace9f814ed79d64a6d2d6f660c4b78d2e39382b8c09"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pytorch19cu11': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
